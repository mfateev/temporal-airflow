"""Temporal workflow for executing Airflow DAGs with deep integration."""
from __future__ import annotations

import asyncio
import weakref
from datetime import datetime, timedelta
from typing import Any

from temporalio import workflow
from temporalio.exceptions import ApplicationError, ActivityError

# Pass through Airflow imports to avoid sandbox reloading issues
with workflow.unsafe.imports_passed_through():
    import pendulum  # Must be imported first to avoid metaclass conflicts
    from airflow.models.dagrun import DagRun, DagRunState
    from airflow.models.dag_version import DagVersion
    from airflow.models.taskinstance import TaskInstance, TaskInstanceState
    from airflow.models.trigger import Trigger  # Required for TaskInstance foreign key
    from airflow.models.tasklog import LogTemplate  # Required for DagRun foreign key
    from airflow.serialization.serialized_objects import DagSerialization
    from airflow._shared.timezones import timezone as airflow_timezone
    from airflow.utils.time_provider import set_time_provider, clear_time_provider
    from sqlalchemy import create_engine
    from sqlalchemy.pool import StaticPool
    from sqlalchemy.orm import sessionmaker
    from airflow.models import Base

from temporal_airflow.models import (
    DeepDagExecutionInput,
    DagExecutionResult,
    DagExecutionFailureDetails,
    ActivityTaskInput,
    TaskExecutionResult,
    TaskExecutionFailureDetails,
    CreateDagRunInput,
    TaskStatusSync,
    BatchTaskStatusSync,
    DagRunStatusSync,
    LoadSerializedDagInput,
    EnsureTaskInstancesInput,
)
from temporal_airflow.activities import run_airflow_task
from temporal_airflow.sync_activities import (
    create_dagrun_record,
    sync_task_status,
    sync_task_status_batch,
    sync_dagrun_status,
    load_serialized_dag,
    ensure_task_instances,
)


@workflow.defn(name="execute_airflow_dag_deep", sandboxed=False)
class ExecuteAirflowDagDeepWorkflow:
    """
    Temporal workflow for deep integration mode.

    Design: Same as standalone workflow + sync activities.

    SAME as standalone workflow:
    - Uses in-workflow database (in-memory SQLite)
    - Uses Airflow's native scheduling logic (update_state, TriggerRuleDep)
    - Creates real DagRun/TaskInstance models in workflow DB

    ADDED for deep integration:
    - Loads DAG from real Airflow DB (via activity)
    - Syncs status to real Airflow DB (via activities)
    - Connections/variables read from real DB by hooks

    Memory cleanup on cache eviction:
        Uses weakref.finalize to register engine.dispose() callback when workflow
        instance is garbage collected (happens when evicted from Temporal's sticky
        cache). This prevents in-memory SQLite databases from leaking memory.

        See _initialize_database() for implementation.
    """

    def __init__(self):
        """Initialize workflow state."""
        # In-workflow database (same as standalone)
        self.engine = None
        self.sessionFactory = None

        # DAG state
        self.dag = None
        self.dag_fileloc: str | None = None

        # Deep integration state
        self.run_id: str | None = None

        # XCom state in workflow (for passing to activities)
        self.xcom_store: dict[tuple, Any] = {}  # ti_key -> xcom_data

        # Task tracking
        self.tasks_succeeded: int = 0
        self.tasks_failed: int = 0

    def _initialize_database(self):
        """
        Initialize workflow-specific in-memory database.

        Each workflow execution gets a fresh database. We use workflow_id + run_id
        to create unique databases per execution. The run_id changes on continue-as-new
        but stays the same during replay of the same execution.

        IMPORTANT: We drop all tables first to handle replay scenarios where
        the in-memory database may have stale data from a previous replay attempt
        within the same worker process.
        """
        workflow_id = workflow.info().workflow_id
        run_id = workflow.info().run_id
        # Use both workflow_id and run_id for unique database per execution
        db_name = f"memdb_{workflow_id}_{run_id}".replace("-", "_")
        conn_str = f"sqlite:///file:{db_name}?mode=memory&cache=shared&uri=true"

        # Create workflow-specific engine (no global state!)
        self.engine = create_engine(
            conn_str,
            poolclass=StaticPool,
            connect_args={"check_same_thread": False},
        )

        # Register cleanup callback for when workflow is garbage collected
        # (happens when evicted from Temporal's sticky cache)
        # NOTE: The callback must NOT reference self to avoid preventing GC
        def _dispose_engine(engine, db_name):
            engine.dispose()
            # workflow.logger is not available here, uncomment for debugging:
            # print(f"[CLEANUP] Disposed engine for {db_name}")

        self._db_cleanup = weakref.finalize(self, _dispose_engine, self.engine, db_name)

        # Create workflow-specific session factory
        self.sessionFactory = sessionmaker(
            bind=self.engine,
            autoflush=False,
            autocommit=False,
            expire_on_commit=False,
        )

        # Create only the tables we need (not all Airflow tables)
        # This avoids the deadlock from creating hundreds of tables
        # Order matters for foreign key dependencies
        required_tables = [
            LogTemplate.__table__,  # DagRun.log_template_id FK
            DagVersion.__table__,   # DagRun.dag_version_id FK
            Trigger.__table__,      # TaskInstance.trigger_id FK
            DagRun.__table__,
            TaskInstance.__table__,
        ]

        # Drop and recreate only required tables to ensure fresh state on replay
        for table in required_tables:
            table.drop(self.engine, checkfirst=True)
        for table in required_tables:
            table.create(self.engine, checkfirst=True)

        # Create a LogTemplate record - DagRun has a non-nullable FK to it
        session = self.sessionFactory()
        try:
            log_template = LogTemplate(
                filename="{{ ti.dag_id }}/{{ ti.task_id }}/{{ ts }}/{{ try_number }}.log",
                elasticsearch_id="{{ dag_id }}-{{ task_id }}-{{ run_id }}-{{ map_index }}-{{ try_number }}",
            )
            session.add(log_template)
            session.commit()
        finally:
            session.close()

        workflow.logger.info(f"Database initialized for workflow {workflow_id} (run_id={run_id})")

    def _create_local_dag_run(
        self,
        dag_id: str,
        run_id: str,
        logical_date: datetime,
        conf: dict | None,
    ) -> int:
        """
        Create DagRun and TaskInstances in IN-WORKFLOW database.

        SAME AS STANDALONE: Uses workflow-specific SessionFactory.
        This enables Airflow's native scheduling logic to work.

        Note: The database is always fresh (dropped/recreated in _initialize_database)
        so we don't need to check for existing records.
        """
        session = self.sessionFactory()
        try:
            # Create DagVersion for this execution
            dag_version = DagVersion(
                dag_id=dag_id,
                version_number=1,
            )
            session.add(dag_version)
            session.flush()

            # Create DagRun
            dag_run = DagRun(
                dag_id=dag_id,
                run_id=run_id,
                logical_date=logical_date,
                run_type="manual",
                state=DagRunState.RUNNING,
                conf=conf,
            )
            dag_run.dag = self.dag  # Set DAG reference (required for update_state)
            dag_run.created_dag_version = dag_version  # Link to version

            session.add(dag_run)
            session.flush()

            # Create TaskInstances using Airflow's native method
            dag_run.verify_integrity(session=session, dag_version_id=dag_version.id)

            session.commit()

            workflow.logger.info(
                f"Created local DagRun: {dag_run.id} with {len(dag_run.task_instances)} tasks"
            )
            return dag_run.id
        finally:
            session.close()

    def _get_upstream_xcom(self, ti: TaskInstance, task) -> dict[str, Any] | None:
        """
        Gather XCom values from upstream tasks.

        SAME AS STANDALONE: XCom stored in workflow state.
        """
        if not task.upstream_task_ids:
            return None

        upstream_results = {}
        for upstream_task_id in task.upstream_task_ids:
            upstream_key = (ti.dag_id, upstream_task_id, ti.run_id, ti.map_index)
            if upstream_key in self.xcom_store:
                upstream_results[upstream_task_id] = self.xcom_store[upstream_key]

        return upstream_results if upstream_results else None

    async def _ensure_dagrun_in_airflow_db(self, input: DeepDagExecutionInput):
        """
        Ensure DagRun and TaskInstances exist in real Airflow DB.

        If input.run_id is provided, uses existing DagRun and ensures TaskInstances exist.
        Otherwise, creates a new DagRun in the real Airflow DB.

        Sets self.run_id as a side effect.
        """
        if input.run_id:
            # DagRun already exists (e.g., created by orchestrator)
            self.run_id = input.run_id
            workflow.logger.info(f"Using existing DagRun: {self.run_id}")

            # Ensure TaskInstances exist in real DB
            await workflow.execute_activity(
                ensure_task_instances,
                EnsureTaskInstancesInput(
                    dag_id=input.dag_id,
                    run_id=self.run_id,
                ),
                start_to_close_timeout=timedelta(seconds=30),
                summary=f"Ensure TIs: {input.dag_id}/{self.run_id[:8]}",
            )
        else:
            # Create new DagRun in real Airflow DB
            result = await workflow.execute_activity(
                create_dagrun_record,
                CreateDagRunInput(
                    dag_id=input.dag_id,
                    logical_date=input.logical_date,
                    conf=input.conf,
                ),
                start_to_close_timeout=timedelta(seconds=30),
                summary=f"Create DagRun: {input.dag_id}",
            )
            self.run_id = result.run_id
            workflow.logger.info(f"Created DagRun in real DB: {self.run_id}")

    @workflow.run
    async def run(self, input: DeepDagExecutionInput) -> DagExecutionResult:
        """
        Execute the DAG with deep integration to Airflow DB.

        Args:
            input: Workflow input with dag_id, logical_date, optional run_id

        Returns:
            DagExecutionResult with final state and statistics
        """
        workflow.logger.info(
            f"Starting deep integration workflow: {input.dag_id} "
            f"(run_id={input.run_id or 'will be created'})"
        )

        # Set Temporal's deterministic time provider for Airflow code
        set_time_provider(workflow.now)

        start_time = workflow.now()

        try:
            # Phase 1: Initialize IN-WORKFLOW database (same as standalone)
            self._initialize_database()

            # Phase 2: Load serialized DAG from REAL Airflow DB (deep integration)
            dag_result = await workflow.execute_activity(
                load_serialized_dag,
                LoadSerializedDagInput(dag_id=input.dag_id),
                start_to_close_timeout=timedelta(seconds=30),
                summary=f"Load DAG: {input.dag_id}",
            )
            # Note: from_dict() is fast (<1ms) when imports are pre-warmed
            # See deep_worker.py _prewarm_imports() which warms up deserialization
            self.dag = DagSerialization.from_dict(dag_result.dag_data)
            self.dag_fileloc = dag_result.fileloc
            workflow.logger.info(
                f"Loaded DAG: {self.dag.dag_id} with {len(self.dag.task_dict)} tasks "
                f"(fileloc={self.dag_fileloc})"
            )

            # Phase 3: Create/verify DagRun in REAL Airflow DB (deep integration)
            await self._ensure_dagrun_in_airflow_db(input)

            # Phase 4: Create DagRun in IN-WORKFLOW database (same as standalone)
            # This enables Airflow's native scheduling logic (update_state, TriggerRuleDep)
            dag_run_id = self._create_local_dag_run(
                dag_id=input.dag_id,
                run_id=self.run_id,
                logical_date=input.logical_date,
                conf=input.conf,
            )

            # Phase 5: Execute scheduling loop with native Airflow logic + sync
            final_state = await self._scheduling_loop(dag_run_id)

            end_time = workflow.now()

            # Phase 6: Sync final state to REAL Airflow DB (deep integration)
            await workflow.execute_activity(
                sync_dagrun_status,
                DagRunStatusSync(
                    dag_id=input.dag_id,
                    run_id=self.run_id,
                    state=final_state,
                    end_date=end_time,
                ),
                start_to_close_timeout=timedelta(seconds=30),
                summary=f"Sync DagRun: {input.dag_id} â†’ {final_state}",
            )

            # If DAG failed, raise ApplicationError
            if final_state == "failed":
                failure_details = DagExecutionFailureDetails(
                    dag_id=input.dag_id,
                    run_id=self.run_id,
                    start_date=start_time,
                    end_date=end_time,
                    tasks_succeeded=self.tasks_succeeded,
                    tasks_failed=self.tasks_failed,
                    error_message=f"DAG execution failed: {self.tasks_failed} task(s) failed",
                )
                raise ApplicationError(
                    f"DAG execution failed: {input.dag_id} / {self.run_id}",
                    failure_details,
                    type="DagExecutionFailure",
                    non_retryable=True,
                )

            return DagExecutionResult(
                state=final_state,
                dag_id=input.dag_id,
                run_id=self.run_id,
                start_date=start_time,
                end_date=end_time,
                tasks_succeeded=self.tasks_succeeded,
                tasks_failed=self.tasks_failed,
            )

        finally:
            clear_time_provider()

    async def _update_local_task_state(self, ti_key: tuple, result: TaskExecutionResult):
        """
        Update TaskInstance in IN-WORKFLOW DB based on activity result.

        This only updates the local in-memory DB. Sync to real Airflow DB
        is done via batched sync_task_status_batch activity.
        """
        session = self.sessionFactory()
        try:
            ti = session.query(TaskInstance).filter(
                TaskInstance.dag_id == ti_key[0],
                TaskInstance.task_id == ti_key[1],
                TaskInstance.run_id == ti_key[2],
                TaskInstance.map_index == ti_key[3],
            ).one()

            # Update in in-workflow DB (same as standalone)
            ti.state = result.state
            ti.start_date = result.start_date
            ti.end_date = result.end_date

            session.commit()

            workflow.logger.info(
                f"Updated local task {ti_key} to state {ti.state} "
                f"(duration: {result.end_date - result.start_date})"
            )
        finally:
            session.close()

    def _check_dag_completion(self, dag_run_id: int) -> str | None:
        """
        Check if DAG run is complete.

        Returns:
            Final state string ("success" or "failed") if complete, None otherwise.
        """
        session = self.sessionFactory()
        try:
            dag_run = session.query(DagRun).filter(DagRun.id == dag_run_id).one()
            if dag_run.state in (DagRunState.SUCCESS, DagRunState.FAILED):
                return dag_run.state.value if hasattr(dag_run.state, 'value') else str(dag_run.state)
            return None
        finally:
            session.close()

    def _get_and_schedule_ready_tasks(self, dag_run_id: int) -> list[TaskInstance]:
        """
        Find schedulable tasks using Airflow's native logic and mark them scheduled.

        Uses dag_run.update_state() which internally calls TriggerRuleDep
        for trigger rule evaluation.

        Returns:
            List of TaskInstance objects ready to execute.
        """
        session = self.sessionFactory()
        try:
            dag_run = session.query(DagRun).filter(DagRun.id == dag_run_id).one()
            dag_run.dag = self.dag

            # CRITICAL: Use Airflow's native update_state() method
            schedulable_tis, _ = dag_run.update_state(
                session=session,
                execute_callbacks=False,
            )
            session.commit()

            if schedulable_tis:
                dag_run.schedule_tis(schedulable_tis, session=session)
                session.commit()

            return schedulable_tis or []
        finally:
            session.close()

    def _start_task_activity(self, ti: TaskInstance, logical_date: datetime) -> tuple[tuple, Any]:
        """
        Start a Temporal activity for a single task instance.

        Args:
            ti: TaskInstance to execute
            logical_date: DAG run's logical date

        Returns:
            Tuple of (ti_key, activity_handle)
        """
        ti_key = (ti.dag_id, ti.task_id, ti.run_id, ti.map_index)

        task = self.dag.get_task(ti.task_id)
        upstream_results = self._get_upstream_xcom(ti, task)
        activity_queue = workflow.info().task_queue

        workflow.logger.info(
            f"Starting activity for {ti_key} on queue '{activity_queue}'"
        )

        handle = workflow.start_activity(
            run_airflow_task,
            arg=ActivityTaskInput(
                dag_id=ti.dag_id,
                task_id=ti.task_id,
                run_id=ti.run_id,
                logical_date=logical_date,
                try_number=ti.try_number,
                map_index=ti.map_index,
                dag_rel_path=self.dag_fileloc,
                upstream_results=upstream_results,
                queue=ti.queue,
                pool_slots=ti.pool_slots,
                connections=None,
                variables=None,
            ),
            task_queue=activity_queue,
            start_to_close_timeout=timedelta(hours=2),
            heartbeat_timeout=timedelta(minutes=5),
            summary=f"Task: {ti.dag_id}.{ti.task_id}",
        )

        return ti_key, handle

    async def _process_activity_result(
        self,
        completed: Any,
        ti_key: tuple,
    ) -> TaskStatusSync | None:
        """
        Process a completed activity and update workflow state.

        Args:
            completed: Completed activity handle
            ti_key: Task instance key tuple

        Returns:
            TaskStatusSync for batching, or None if sync not needed
        """
        try:
            result: TaskExecutionResult = completed.result()
            workflow.logger.info(
                f"Activity completed for {ti_key}: state={result.state}"
            )

            # Store XCom in workflow state
            if result.xcom_data:
                self.xcom_store[ti_key] = result.xcom_data

            # Update task counts
            if result.state == TaskInstanceState.SUCCESS:
                self.tasks_succeeded += 1
            elif result.state == TaskInstanceState.FAILED:
                self.tasks_failed += 1

            # Update in-workflow DB
            await self._update_local_task_state(ti_key, result)

            return TaskStatusSync(
                dag_id=ti_key[0],
                task_id=ti_key[1],
                run_id=self.run_id,
                map_index=ti_key[3],
                state=result.state.value,
                start_date=result.start_date,
                end_date=result.end_date,
                xcom_value=result.return_value if hasattr(result, 'return_value') else None,
            )

        except ActivityError as e:
            workflow.logger.error(
                f"ActivityError for {ti_key}: {e.message}"
            )
            self.tasks_failed += 1

            failed_result = TaskExecutionResult(
                dag_id=ti_key[0],
                task_id=ti_key[1],
                run_id=ti_key[2],
                try_number=1,
                state=TaskInstanceState.FAILED,
                start_date=workflow.now(),
                end_date=workflow.now(),
                error_message=str(e.message),
            )
            await self._update_local_task_state(ti_key, failed_result)

            return TaskStatusSync(
                dag_id=ti_key[0],
                task_id=ti_key[1],
                run_id=self.run_id,
                map_index=ti_key[3],
                state=TaskInstanceState.FAILED.value,
                start_date=failed_result.start_date,
                end_date=failed_result.end_date,
            )

        except Exception as e:
            workflow.logger.error(
                f"Unexpected error for {ti_key}: {type(e).__name__}: {e}"
            )
            self.tasks_failed += 1
            return None

    async def _sync_task_completions(self, syncs: list[TaskStatusSync]):
        """Batch sync completed task states to Airflow DB."""
        if not syncs:
            return

        task_ids = ", ".join(s.task_id for s in syncs[:3])
        summary_suffix = f" +{len(syncs)-3} more" if len(syncs) > 3 else ""

        await workflow.execute_activity(
            sync_task_status_batch,
            BatchTaskStatusSync(syncs=syncs),
            start_to_close_timeout=timedelta(seconds=30),
            summary=f"Sync {len(syncs)} tasks: {task_ids}{summary_suffix}",
        )

    async def _await_and_process_completions(
        self,
        running_activities: dict[tuple, Any],
    ) -> list[tuple]:
        """
        Wait for activities to complete, process results, sync to DB.

        Args:
            running_activities: Dict of ti_key -> activity handle

        Returns:
            List of completed ti_keys to remove from running_activities
        """
        workflow.logger.info(
            f"Waiting for {len(running_activities)} activities..."
        )

        done, pending = await workflow.wait(
            running_activities.values(),
            return_when=asyncio.FIRST_COMPLETED
        )

        workflow.logger.info(
            f"Activity wait: {len(done)} done, {len(pending)} pending"
        )

        # Process completions and collect syncs
        completed_keys = []
        syncs = []

        for completed in done:
            ti_key = next(k for k, v in running_activities.items() if v == completed)
            completed_keys.append(ti_key)

            sync = await self._process_activity_result(completed, ti_key)
            if sync:
                syncs.append(sync)

        # Batch sync to Airflow DB
        await self._sync_task_completions(syncs)

        return completed_keys

    async def _scheduling_loop(self, dag_run_id: int) -> str:
        """
        Main scheduling loop using Airflow's native logic.

        Returns:
            Final DAG run state ("success" or "failed")
        """
        running_activities: dict[tuple, Any] = {}
        logical_date = self._get_logical_date(dag_run_id)

        iteration = 0
        while True:
            iteration += 1
            workflow.logger.info(
                f"Scheduling iteration {iteration}: "
                f"{len(running_activities)} running"
            )

            # Find schedulable tasks (calls update_state() which may mark DAG complete)
            schedulable_tis = self._get_and_schedule_ready_tasks(dag_run_id)

            # Check if DAG is complete (must be AFTER update_state() call)
            final_state = self._check_dag_completion(dag_run_id)
            if final_state:
                workflow.logger.info(f"DAG completed: {final_state}")
                return final_state

            # Start activities for schedulable tasks
            for ti in schedulable_tis:
                ti_key, handle = self._start_task_activity(ti, logical_date)
                running_activities[ti_key] = handle

            # Fail if stuck (no activities to wait for)
            # TODO: When sensors/deferrable operators are implemented,
            # wait for external events (Temporal signals) instead of failing.
            if not running_activities:
                raise ApplicationError(
                    f"Workflow stuck: no running activities but DAG not complete. "
                    f"DAG: {self.dag.dag_id}, run_id: {self.run_id}, "
                    f"succeeded: {self.tasks_succeeded}, failed: {self.tasks_failed}",
                    type="WorkflowStuck",
                    non_retryable=True,
                )

            # Wait for completions
            completed_keys = await self._await_and_process_completions(running_activities)
            for key in completed_keys:
                del running_activities[key]

    def _get_logical_date(self, dag_run_id: int) -> datetime:
        """Get the logical date for a DAG run."""
        session = self.sessionFactory()
        try:
            dag_run = session.query(DagRun).filter(DagRun.id == dag_run_id).one()
            return dag_run.logical_date
        finally:
            session.close()
